{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "966fcb7e",
   "metadata": {},
   "source": [
    "20260124\n",
    "\n",
    "- L1 (Foundation): clean Python, data handling, correctness, basic NLP\n",
    "- L2 (Core): REST services, async, evaluation, retrieval, model wrappers\n",
    "- L3 (Advanced): RAG pipelines, caching, observability, AWS patterns, CI/CD rigor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de2ab1c",
   "metadata": {},
   "source": [
    "# A) python foundations for AI backends (5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746f21cb",
   "metadata": {},
   "source": [
    "## 1. re.sub()\n",
    "(whitespace, casing, punctuation)\n",
    "\n",
    "- Scenario: Chatbot preprocessor cleans user input.\n",
    "- Input: \"  Hi!!   I NEED   help...  \"\n",
    "- Output: \"hi! i need help...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e501b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi!! i need help...\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "def normalize(text:str) -> str:\n",
    "    text = text.strip().lower() # strip(): leading and trailing whitespace removed\n",
    "    text = re.sub(r\"\\s+\", \" \", text)    #collapses any run of whitespace(spaces, tabs, newlines) into a single space\n",
    "    text = re.sub(r\"!{2,}\", \"!\", text)  #collapses any run of 2 or more exclamation marks into a single !\n",
    "    \n",
    "    return text\n",
    "\n",
    "print(normalize(\"  Hi!!   I NEED   help...  \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00349b2",
   "metadata": {},
   "source": [
    "## 2. parse_qsl: kv pairs\n",
    "Parse key=value pairs\n",
    "- Scenario: REST endpoint receives tracking params.\n",
    "- Input: \"lang=en&user=42&debug=true\"\n",
    "- Output: {\"lang\":\"en\",\"user\":\"42\",\"debug\":\"true\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7916561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lang': 'en', 'user': '42', 'debug': 'true'}\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import parse_qsl\n",
    "\n",
    "def  parse_query(q:str) -> dict:\n",
    "    return dict(parse_qsl(q, keep_blank_values=True))\n",
    "\n",
    "print(parse_query(\"lang=en&user=42&debug=true\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff750a33",
   "metadata": {},
   "source": [
    "## 3. pathlib, Path\n",
    "Safe JSON read + validation fallback\n",
    "- Scenario: Load prompt templates from JSON; donâ€™t crash on bad file.\n",
    "- Input: bad JSON file\n",
    "- Output: default dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db62b7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'system': 'You are helpful.'}\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "from pathlib import Path \n",
    "\n",
    "def load_json(path: str, default: dict) -> dict:\n",
    "    try:\n",
    "        return json.loads(Path(path).read_text(encoding=\"utf-8\"))\n",
    "    except(OSError, json.JSONDecodeError):\n",
    "        return default \n",
    "\n",
    "cfg = load_json(\"prompts.json\", {\"system\": \"You are helpful.\"})\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f73c028e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: tmp/profile.json\n",
      "File contents:\n",
      " {\n",
      "  \"id\": 7,\n",
      "  \"tags\": [\n",
      "    \"new\",\n",
      "    \"vip\"\n",
      "  ],\n",
      "  \"active\": true\n",
      "}\n",
      "Loaded: {'id': 7, 'tags': ['new', 'vip'], 'active': True}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "user = {\"id\": 7, \"tags\": [\"new\", \"vip\"], \"active\": True}\n",
    "\n",
    "p = Path(\"tmp\") / \"profile.json\"\n",
    "p.parent.mkdir(exist_ok=True)\n",
    "\n",
    "p.write_text(json.dumps(user, indent=2))\n",
    "\n",
    "print(\"Saved to:\", p)\n",
    "print(\"File contents:\\n\", p.read_text())\n",
    "\n",
    "loaded = json.loads(p.read_text())\n",
    "print(\"Loaded:\", loaded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da68c3a",
   "metadata": {},
   "source": [
    "## 4. set() to deduplicate\n",
    "Deduplicate events while preserving order\n",
    "- Scenario: Avoid double-counting telemetry events.\n",
    "- Input: [\"open\",\"click\",\"open\",\"close\"]\n",
    "- Output: [\"open\",\"click\",\"close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7538458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['open', 'click', 'close']\n"
     ]
    }
   ],
   "source": [
    "from typing import List \n",
    "\n",
    "def dedupe_keep_order(items: List) -> List:\n",
    "    seen, out = set(), []   # ðŸ¤© Set for O(1), order preservation\n",
    "    for x in items:\n",
    "        if x not in seen:\n",
    "            seen.add(x)\n",
    "            out.append(x)\n",
    "    return out \n",
    "\n",
    "print(dedupe_keep_order([\"open\",\"click\",\"open\",\"close\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d74d3513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "# key point: set() only contains unique values\n",
    "\n",
    "s = {1,1,2,3,3}\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9ec2f4",
   "metadata": {},
   "source": [
    "## 5. @lru_cache\n",
    "\n",
    "Simple LRU cache for expensive operations\n",
    "- Scenario: cache embeddings or database lookups\n",
    "- input: repeated key\n",
    "- output: avoids recomputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edadc343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_for_order_1\n",
      "result_for_order_1\n"
     ]
    }
   ],
   "source": [
    "from functools import lru_cache # to memoize results of a function so repeated calls with the same input are fast. (LRU = least reacently used)\n",
    "\n",
    "@lru_cache(maxsize=1024)    #wraps the function with a cache that stores up to 1024 recent results.\n",
    "def expensive_lookup(key: str) -> str:\n",
    "    # pretend DB/ network call\n",
    "    return f\"result_for_{key}\"\n",
    "\n",
    "\n",
    "print(expensive_lookup(\"order_1\"))  #firstcall with \"order_1\" computes and stores the result\n",
    "print(expensive_lookup(\"order_1\"))  #cached (same key, so served from cache. no DB/network work)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdab144",
   "metadata": {},
   "source": [
    "# B) Data processing with scientific stack (Numpy/pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64afcaa2",
   "metadata": {},
   "source": [
    "## 6. pd.Series, s.str.len()\n",
    "Compute basic text stats with pandas\n",
    "- scenario: analyze chat logs\n",
    "- list of messages\n",
    "- avg length, empty rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2b387cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                       hi\n",
      "1    need help with refund\n",
      "2                         \n",
      "3                   thanks\n",
      "dtype: str\n",
      "0     2\n",
      "1    21\n",
      "2     0\n",
      "3     6\n",
      "dtype: int64\n",
      "{'avg_len': np.float64(7.25), 'empty_rate': np.float64(0.25)}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "msgs = [\"hi\", \"need help with refund\", \"\", \"thanks\"]\n",
    "s = pd.Series(msgs) #create a 1d labeled array\n",
    "print(s)\n",
    "print(s.str.len())\n",
    "\n",
    "stats = {\n",
    "    \"avg_len\": s.str.len().mean(),  #adding \"float()\" also correct\n",
    "    \"empty_rate\":(s.str.len() == 0).mean()\n",
    "}\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5991aa",
   "metadata": {},
   "source": [
    "- don't know why my terminal venv is not the same as the one i use in ipynb, so...i tried to directly use :\n",
    "    - ./.venv/bin/python -m pip install pandas\n",
    "- to install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e7bcae",
   "metadata": {},
   "source": [
    "## 7. pd.to_datetime(), datetime\n",
    "date parsing + timezone normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3750fa16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-24T09:20:00+00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "ts = pd.to_datetime(\"2026-01-24T10:20:00+01:00\", utc=True)  #Parses the ISO string into a pandas Timestamp; utc=True converts the result to UTC time\n",
    "print(ts.isoformat())   # Prints the timestamp in ISO 8601 format (now in UTC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa9cf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-24T09:20:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# can also use datetime\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "ts = datetime.fromisoformat(\"2026-01-24T10:20:00+01:00\")    #parse ISo string into timezone-aware datetime object\n",
    "ts_utc = ts.astimezone(timezone.utc)    #since ts is now a datetime object. astimezone is a method of the OBJECT\n",
    "print(ts_utc.isoformat())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c31dc2",
   "metadata": {},
   "source": [
    "## 8. into batches (Iterable)\n",
    "- scenario: send documents to embedding api in batches\n",
    "- input: docs size=10, batch=4\n",
    "- output: 3 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc14b62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 'b', 'c', 'd'], ['e', 'f', 'g', 'h'], ['i', 'j']]\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Iterable\n",
    "\n",
    "def batched(items: List[str], size:int) -> Iterable[List[str]]: #Iterable: a type hint for \"anything you can loop over\"(list, tuple, set, generator, etc.) so it can be List[List[str]], or Tuple(List[str]) or etc.\n",
    "    for i in range(0, len(items), size):\n",
    "        yield items[i:i+size]\n",
    "\n",
    "print(list(batched(list(\"abcdefghij\"),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8162270c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g']\n"
     ]
    }
   ],
   "source": [
    "print(list(\"abcdefg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc594966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "15\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "# another Iterable example\n",
    "from typing import Iterable\n",
    "\n",
    "def total(nums: Iterable[int]) -> int:  #Iterable[int] means it can be anything like list, tuple or set, as long as it can be iterated\n",
    "    s = 0\n",
    "    for n in nums:\n",
    "        s += n\n",
    "    return s\n",
    "\n",
    "print(total([1, 2, 3]))     # list\n",
    "print(total((4, 5, 6)))     # tuple\n",
    "print(total({7, 8, 9}))     # set\n",
    "\n",
    "# non-iterables: int, float, None, bool, a plain object() instance\n",
    "\n",
    "# as long as it is an iterable object, we can apply for loop on it. (lists, tuples, sets, strings, dicts, generators, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4e248e",
   "metadata": {},
   "source": [
    "## 9. np.lianalg.norm()\n",
    "\n",
    "cosine similarity with numpy (no sklearn)\n",
    "- scenario: rank candidates by embedding similarity\n",
    "- input: query vec + candidate vecs\n",
    "- output: best index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f10c7458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [0.9938837346715274, 0.0, 0.9999999999979998]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def best_match(q, X):\n",
    "    q = np.array(q, dtype=float)\n",
    "    X = np.array(X, dtype=float)\n",
    "    \n",
    "    qn = q / (np.linalg.norm(q) + 1e-12)\n",
    "    Xn = X / (np.linalg.norm(X, axis=1, keepdims=True) + 1e-12)\n",
    "    \n",
    "    sims = Xn @ qn \n",
    "    return int(np.argmax(sims)), sims.tolist()\n",
    "\n",
    "idx, sims = best_match([1,0], [[0.9,0.1], [0,1],[1,0]])\n",
    "print(idx,sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641f6b2f",
   "metadata": {},
   "source": [
    "## 10. for _,row in x.iterrows()\n",
    "streaming csv processing (memory-safe)\n",
    "- scenario: rag on large csv kb; avoid loading full file\n",
    "- input: csv path\n",
    "- output: yields filtered rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a218c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "def iter_rows(path: str, keyword: str):\n",
    "    for chunk in pd.read_csv(path, chunsize=1000):\n",
    "        hit = chunk[chunk[\"text\"].str.contains(keyword, na=False)]\n",
    "        for _, row in hit.iterrows():\n",
    "            yield row.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687e1dff",
   "metadata": {},
   "source": [
    "# C) Core NLP with NLTK / spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7661e80a",
   "metadata": {},
   "source": [
    "## 11. re.findall()\n",
    "\n",
    "Tokenization with regex (no library)\n",
    "- Scenario: Minimal dependency service.\n",
    "- Input: \"Refund for order #123?\"\n",
    "- Output: [\"refund\",\"for\",\"order\",\"123\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ab7e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['refund', 'for', 'order', '123']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(text: str):\n",
    "    return re.findall(r\"[a-z0-9]+\", text.lower())\n",
    "\n",
    "print(tokenize(\"Refund for order #123?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ebda60",
   "metadata": {},
   "source": [
    "\n",
    "spaCy NER extraction for support tickets\n",
    "\n",
    "- Scenario: Extract ORG/PRODUCT from ticket text.\n",
    "- Input: \"Issue with Apple Pay on iPhone 15\"\n",
    "- Output: entities list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ab8fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue with Apple Pay on iPhone 15\n",
      "[('Apple Pay', 'ORG'), ('15', 'CARDINAL')]\n"
     ]
    }
   ],
   "source": [
    "# ./.venv/bin/python -m pip install pandas\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")  #includes a tokenizer and NER component (named entity recognition)\n",
    "\n",
    "def extract_ents(text: str):\n",
    "    doc = nlp(text)\n",
    "    print(doc)  #nothing will happen, still itself\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents] #detect entity and label pairs in the doc\n",
    "\n",
    "print(extract_ents(\"Issue with Apple Pay on iPhone 15\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe75e00f",
   "metadata": {},
   "source": [
    "## TfidfVectorizer & LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff182c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shipping\n"
     ]
    }
   ],
   "source": [
    "# should first install wheel and sciket-learn:  ./.venv/bin/python -m pip install -U pip setuptools wheel; ./.venv/bin/python -m pip install scikit-learn\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = [\"where is my package\", \"i want a refund\", \"track my delivery\", \"refund please\"]\n",
    "y = [\"shipping\",\"refund\",\"shipping\",\"refund\"]\n",
    "\n",
    "clf = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"lr\", LogisticRegression(max_iter=1000))\n",
    "]).fit(X, y)\n",
    "\n",
    "print(clf.predict([\"can i get my money back?\"])[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca8b4d2",
   "metadata": {},
   "source": [
    "## classification_report: precision, recall, f1score,support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "680dd1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      refund      0.667     1.000     0.800         2\n",
      "    shipping      0.000     0.000     0.000         1\n",
      "\n",
      "    accuracy                          0.667         3\n",
      "   macro avg      0.333     0.500     0.400         3\n",
      "weighted avg      0.444     0.667     0.533         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilun.zhang/VSCodeProjects/aie/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lilun.zhang/VSCodeProjects/aie/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lilun.zhang/VSCodeProjects/aie/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = [\"refund\",\"shipping\",\"refund\"]\n",
    "y_pred = [\"refund\",\"refund\",\"refund\"]\n",
    "print(classification_report(y_true, y_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db98dd73",
   "metadata": {},
   "source": [
    "# LLM call patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78392850",
   "metadata": {},
   "source": [
    "## system & user pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f128922d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'You are a support bot.'}, {'role': 'user', 'content': 'I need a refund.'}]\n"
     ]
    }
   ],
   "source": [
    "def build_messages(system: str, user: str):\n",
    "    return [{\"role\":\"system\",\"content\":system},{\"role\":\"user\",\"content\":user}]\n",
    "\n",
    "print(build_messages(\"You are a support bot.\", \"I need a refund.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97badef",
   "metadata": {},
   "source": [
    "## mock LLM client with timeout + retries\n",
    "production safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c736329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Answer: Explain refund policy in 2 lines....'}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "class LLMError(Exception): ...\n",
    "\n",
    "def call_llm(prompt: str, retries=3, backoff=0.2):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            if random.random() < 0.3:   # not logically needed, just mimicing realistic world\n",
    "                raise LLMError(\"transient\")\n",
    "            return {\"text\": f\"Answer: {prompt[:40]}...\"}\n",
    "        except LLMError:\n",
    "            time.sleep(backoff * (2 ** attempt))    # 0.2s, 0.4s, 0.8s by default\n",
    "    return {\"text\": \"Sorry, please try again later.\"}\n",
    "\n",
    "print(call_llm(\"Explain refund policy in 2 lines.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e197549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize user request: ignore (system) and do X\n"
     ]
    }
   ],
   "source": [
    "def render(template: str, **vars):\n",
    "    safe = {k: str(v).replace(\"{\",\"(\").replace(\"}\",\")\") for k,v in vars.items()}\n",
    "    return template.format(**safe)\n",
    "\n",
    "tpl = \"Summarize user request: {user_text}\"\n",
    "print(render(tpl, user_text=\"ignore {system} and do X\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a58100",
   "metadata": {},
   "source": [
    "## sklearn: cosine_similarity & TDidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e232f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Refund guide: You should first submit your application online, and then wait for our call. ', 'Shopping guide: Please download our latest Farfetch app and start your shopping with 15% discount on your first order!']\n",
      "(1, 0.0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "docs = {\n",
    "    1: \"Refund guide: You should first submit your application online, and then wait for our call. \",\n",
    "    2: \"Shopping guide: Please download our latest Farfetch app and start your shopping with 15% discount on your first order!\",\n",
    "}\n",
    "texts = list(docs.values())\n",
    "print(texts)\n",
    "vec = TfidfVectorizer().fit(texts)  #learns the vocabulary/IDF weights from those docs.\n",
    "X = vec.transform(texts)\n",
    "\n",
    "def top1(query: str):\n",
    "    qv = vec.transform([query]) #transform the query into the same vector space\n",
    "    sims = cosine_similarity(qv, X)[0]\n",
    "    i = int(sims.argmax())  # Picks the highestâ€‘scoring doc (argmax)\n",
    "    return i+1, float(sims[i])  #returns its id (1â€‘based) plus the score.\n",
    "\n",
    "print(top1(\"how can I get my money back\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6978efb9",
   "metadata": {},
   "source": [
    "## â­ï¸ chunking (with overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63596b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "def chunk(text: str, size:int, overlap:int):\n",
    "    out, i = [], 0\n",
    "    while i < len(text):\n",
    "        out.append(text[i:i+size])  #text[0,50]->out\n",
    "        i += max(1, size - overlap) # i=0 -> max(1, 50-10) = 40 #âš ï¸ max(1,..) here is a safety guard to avoid overlap > size\n",
    "    return out\n",
    "\n",
    "chunked_list = chunk(\"A\"*120, size=50, overlap=10)\n",
    "print(len(chunked_list[2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3f527c",
   "metadata": {},
   "source": [
    "## chunking with metadata\n",
    "filtering before expensive scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e3c9f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "chunks = [\n",
    "  {\"id\":\"r1\",\"domain\":\"refund\",\"text\":\"refund within 7 days\"},\n",
    "  {\"id\":\"s1\",\"domain\":\"shipping\",\"text\":\"shipping takes 3-5 days\"},\n",
    "]\n",
    "\n",
    "def filter_domain(items, domain):\n",
    "    return [x for x in items if x[\"domain\"] == domain]  #we use [] here to avoid raising error âš ï¸\n",
    "    # else:\n",
    "    #     raise ValueError(\"No such domain!\")\n",
    "\n",
    "print(filter_domain(chunks, \"shopping\"))    #if domain not in the chunks, it will return a [] ðŸ¤©\n",
    "\n",
    "# [] doesn't raise error!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1254379",
   "metadata": {},
   "source": [
    "## âœ… confidence gate\n",
    "if similarity score is too low, we don't go to retrieval stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3cc24b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ask_clarify\n"
     ]
    }
   ],
   "source": [
    "def decide(scores: List, thr: int) -> str:\n",
    "    best = max(scores) if scores else 0.0\n",
    "    \n",
    "    return \"use_rag\" if best >= thr else \"ask_clarify\"\n",
    "\n",
    "print(decide([0.42, 0.31], 0.55))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75985113",
   "metadata": {},
   "source": [
    "## â­ï¸ hybrid retrieval: keyword + TF-IDF union\n",
    "- scenario: improve recall for short queries\n",
    "- input: \"refund receipt\"\n",
    "- output: merged candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb38c2c",
   "metadata": {},
   "source": [
    "Add all document IDs related to word w into the candidate set c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21a0fe40",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      9\u001b[39m     tdidf_top, _ = top1(query)\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(kw | {tdidf_top})\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mhybrid\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrefund receipt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mhybrid\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhybrid\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     kw = \u001b[43mkeyword_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     tdidf_top, _ = top1(query)\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(kw | {tdidf_top})\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mkeyword_candidates\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m      2\u001b[39m c = \u001b[38;5;28mset\u001b[39m()\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m query.lower().split():\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     c |= \u001b[43mindex\u001b[49m.get(w,\u001b[38;5;28mset\u001b[39m())\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "\u001b[31mNameError\u001b[39m: name 'index' is not defined"
     ]
    }
   ],
   "source": [
    "def keyword_candidates(query: str):\n",
    "    c = set()\n",
    "    for w in query.lower().split():\n",
    "        c |= index.get(w,set())\n",
    "    return c \n",
    "\n",
    "def hybrid(query: str):\n",
    "    kw = keyword_candidates(query)\n",
    "    tdidf_top, _ = top1(query)\n",
    "    \n",
    "    return sorted(kw | {tdidf_top})\n",
    "\n",
    "hybrid(\"refund receipt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c63738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

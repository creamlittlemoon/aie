{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c6e5ef2",
   "metadata": {},
   "source": [
    "# general checks for these cases (what variables to make)\n",
    "- 1. boundaries\n",
    "- 2. window state: when you MUST know about the current window\n",
    "- 3. best-so-far\n",
    "- 4. constraints/targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7067a5c6",
   "metadata": {},
   "source": [
    "# chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a83a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo for chunking\n",
    "# can't run\n",
    "for i in range(0,n,k):\n",
    "    chunk = arr[i:i+k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28efd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def chunk(text: str, size=50, overlap=10):\n",
    "    out, i = [], 0\n",
    "    while i < len(text):\n",
    "        out.append(text[i:i+size])  #text[0,50]->out\n",
    "        i += max(1, size - overlap) # i=0 -> max(1, 50-40) = 40\n",
    "    return out\n",
    "    \n",
    "chunked_list = chunk(\"A\"*120, size=50, overlap=10)\n",
    "print(len(chunked_list[2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1546ffe5",
   "metadata": {},
   "source": [
    "# sliding window\n",
    "clues are often üëáüèª\n",
    "- 1. subarray/substring\n",
    "- 2. longest/shortest\n",
    "- 3. at most/at least\n",
    "- 4. continuous segment/consecutive (12 values for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12d62dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo code for sliding window\n",
    "# can't run \n",
    "\n",
    "left = 0\n",
    "for right in range(n):\n",
    "    # expand\n",
    "    while invalid:\n",
    "        left += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80ca46d",
   "metadata": {},
   "source": [
    "# inverted index\n",
    "This is the foundational structure behind search engines, keyword recall, RAG systems, and hybrid retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6802ac8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{1, 2}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "docs = {\n",
    "    1: \"refund policy and receipt\",\n",
    "    2: \"how to request a refund\",\n",
    "    3: \"lost receipt replacement\"\n",
    "}\n",
    "\n",
    "index = defaultdict(set)\n",
    "print(list(index))  #[]\n",
    "\n",
    "for doc_id, text in docs.items():   #kv pairs\n",
    "    for word in text.lower().split():\n",
    "        index[word].add(doc_id)\n",
    "\n",
    "print(index[\"refund\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bdbabd",
   "metadata": {},
   "source": [
    "# class cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6fdc3",
   "metadata": {},
   "source": [
    "## RAG pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859355d6",
   "metadata": {},
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9994683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_score = [s for s in score if 0 <= s <= 1] # get pure score\n",
    "scored = [(c, mock_similarity(query, c.text)) for c in chunks]  #get (related_part_in_doc, similarity_score) pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7d116ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer to 'refund policy' using 1 docs.\n"
     ]
    }
   ],
   "source": [
    "class Retriever:\n",
    "    def retrieve(self, query):\n",
    "        return [f\"doc about {query} (score=0.82)\"]\n",
    "\n",
    "class Generator:\n",
    "    def generate(self, query, docs):\n",
    "        return f\"Answer to '{query}' using {len(docs)} docs.\"\n",
    "\n",
    "class RAGPipeline:\n",
    "    def __init__(self, retriever, generator):\n",
    "        self.retriever = retriever\n",
    "        self.generator = generator\n",
    "\n",
    "    def run(self, query):\n",
    "        docs = self.retriever.retrieve(query)\n",
    "        return self.generator.generate(query, docs)\n",
    "\n",
    "pipe = RAGPipeline(Retriever(), Generator())\n",
    "print(pipe.run(\"refund policy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d572428",
   "metadata": {},
   "source": [
    "chunking with overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c9c17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 manual_cn_c0 600\n"
     ]
    }
   ],
   "source": [
    "# eg. for a 50,000 chinese character document\n",
    "# can't run\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "@dataclass\n",
    "class Chunk:\n",
    "    chunk_id: str\n",
    "    text: str\n",
    "    meta: Dict[str, Any]  # e.g. {\"section\": \"4.2\", \"page\": 12}\n",
    "\n",
    "def chunk_text_by_chars(\n",
    "    doc_text: str,\n",
    "    chunk_size: int = 600,\n",
    "    overlap: int = 120,\n",
    "    doc_id: str = \"doc1\"\n",
    ") -> List[Chunk]:\n",
    "    \"\"\"\n",
    "    Character-based chunking (works well for Chinese).\n",
    "    \"\"\"\n",
    "    assert 0 <= overlap < chunk_size        # ü§©use of assert here\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    idx = 0\n",
    "    while start < len(doc_text):\n",
    "        end = min(len(doc_text), start + chunk_size)\n",
    "        text = doc_text[start:end].strip()\n",
    "        if text:\n",
    "            chunks.append(Chunk(\n",
    "                chunk_id=f\"{doc_id}_c{idx}\",\n",
    "                text=text,\n",
    "                meta={\"doc_id\": doc_id, \"start\": start, \"end\": end}\n",
    "            ))\n",
    "            idx += 1\n",
    "        start += (chunk_size - overlap)\n",
    "    return chunks\n",
    "\n",
    "# Example\n",
    "doc = \"ÔºàÂÅáËÆæËøôÈáåÊòØÂæàÈïøÁöÑ‰∏≠ÊñáÊñáÊ°£...Ôºâ\" * 5000\n",
    "chunks = chunk_text_by_chars(doc, chunk_size=600, overlap=120, doc_id=\"manual_cn\")\n",
    "print(len(chunks), chunks[0].chunk_id, len(chunks[0].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8b947d",
   "metadata": {},
   "source": [
    "List[Chunk] meaning visually üëáüèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2394c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks: List[Chunk] = [\n",
    "    Chunk(\"c0\", \"a\", 0, 1),\n",
    "    Chunk(\"c1\", \"b\", 1, 2),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f7f33b",
   "metadata": {},
   "source": [
    "## agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a78f2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crewai example\n",
    "\n",
    "searcher = Agent(\n",
    "    role='Content Searcher',\n",
    "    goal='Search for online content about {topic}',\n",
    "    backstory='''\n",
    "        You will be working on creating articles for LinkedIn about {topic}. \n",
    "        You will conduct research online, collect and group information. \n",
    "        Your work will serve as a basis for the Content Writer.\n",
    "    ''',\n",
    "    llm=my_llm,\n",
    "    verbose=True,       # if detailed logging needed\n",
    "    allow_delegate=False,\n",
    "    tools=[search_tool]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c811488",
   "metadata": {},
   "source": [
    "aside from that, we need to define Task for each agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc37f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eg, for the Search Agent \n",
    "search = Task(\n",
    "    description='''\n",
    "        1. Give priority to the most recent trends, key figures, \n",
    "           and breaking news related to {topic}.\n",
    "        2. Determine the target audience, taking into account \n",
    "           their interests and challenges.\n",
    "        3. Incorporate SEO keywords and data from credible sources.\n",
    "    ''',\n",
    "    agent=searcher,\n",
    "    expected_output='A comprehensive trend plan focused on {topic}, incorporating top SEO keywords and the most recent news.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2c9da7",
   "metadata": {},
   "source": [
    "in multi-agent mode, we shall ensemble the crew at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b1afc5",
   "metadata": {},
   "source": [
    "## multiagent & crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2168cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "crew = Crew(\n",
    "    agents=[searcher, writer, editor],\n",
    "    tasks=[search, write, review],\n",
    "    verbose=1,\n",
    "    process=Process.sequential\n",
    "    memory=True      # enable crew memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8aca79",
   "metadata": {},
   "source": [
    "# fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f312170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.post(\"/chat/data_sql_chat\",\n",
    "             tags=[\"Chat\"],\n",
    "             summary=\"‰∏éÂÖÉËä≥Áõ¥Êé•ÂØπËØùËøîÂõûSQL(ÈÄöËøáÂ§öÊÆµËØ∑Ê±Ç)\",\n",
    "             )(data_sql_chat)\n",
    "\n",
    "    app.post(\"/chat/chat\",\n",
    "             tags=[\"Chat\"],\n",
    "             summary=\"‰∏éllmÊ®°ÂûãÂØπËØù(ÈÄöËøáLLMChain)\",\n",
    "             )(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036b21b7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4a388b5",
   "metadata": {},
   "source": [
    "20260211\n",
    "recording some nlp tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea96e98f",
   "metadata": {},
   "source": [
    "use anchor in sentence similarity comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9ac66ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilun.zhang/VSCodeProjects/aie/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1104.34it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.36162615 0.5896069  0.03221758]]\n"
     ]
    }
   ],
   "source": [
    "# don't know, should always use: ./.venv//bin/python -m pip install sentence_transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    " \n",
    "# Initialize model and encode anchors\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "anchors = [\"billing issue\", \"login problem\", \"feature request\"]\n",
    "anchor_embeddings = model.encode(anchors)\n",
    " \n",
    "# Encode a new ticket\n",
    "new_ticket = [\"I can't access my account, it says password invalid.\"]\n",
    "ticket_embedding = model.encode(new_ticket)\n",
    " \n",
    "# Calculate similarity features\n",
    "similarity_features = cosine_similarity(ticket_embedding, anchor_embeddings)\n",
    "print(similarity_features)  # e.g., [[0.1, 0.85, 0.3]] -> high similarity to \"login problem\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a72b8f",
   "metadata": {},
   "source": [
    "try business case（used for text classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928872c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 975.10it/s, Materializing param=pooler.dense.weight]                               \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: shibing624/text2vec-base-chinese\n",
      "Key                          | Status     |  | \n",
      "-----------------------------+------------+--+-\n",
      "bert.embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.36438686 0.42217815]]\n"
     ]
    }
   ],
   "source": [
    "# don't know, should always use: ./.venv//bin/python -m pip install sentence_transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    " \n",
    "# Initialize model and encode anchors\n",
    "model = SentenceTransformer('shibing624/text2vec-base-chinese')\n",
    "anchors = [\"买车\", \"没提到要买车\"]\n",
    "anchor_embeddings = model.encode(anchors)\n",
    " \n",
    "# Encode a new ticket\n",
    "new_ticket = [\"ET9展车已到门店，从兰州新区接送用户到万象城门店看车，单程60公里\"]\n",
    "ticket_embedding = model.encode(new_ticket)\n",
    " \n",
    "# Calculate similarity features\n",
    "similarity_features = cosine_similarity(ticket_embedding, anchor_embeddings)\n",
    "print(similarity_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc92b53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 1021.08it/s, Materializing param=pooler.dense.weight]                              \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: shibing624/text2vec-base-chinese\n",
      "Key                          | Status     |  | \n",
      "-----------------------------+------------+--+-\n",
      "bert.embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5112165  0.5099434  0.42966738]]\n"
     ]
    }
   ],
   "source": [
    "# 测试：能否提取几种汽车品牌，不准。觉得是too specific。比如上面这种general带语义的判断结果还ok。\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    " \n",
    "# Initialize model and encode anchors\n",
    "model = SentenceTransformer('shibing624/text2vec-base-chinese')\n",
    "anchors = [\"提到多个汽车品牌\", \"仅提到一种汽车品牌\", \"未提到汽车品牌\"]\n",
    "anchor_embeddings = model.encode(anchors)\n",
    " \n",
    "# Encode a new ticket\n",
    "new_ticket = [\"用户是经常在国外，但是一直有在炒股，比较关注蔚来，每次有新车型上市都会关心讨论。用户也接触过好几个顾问，但是觉得回复速度和专业性会差一些，比较认可我们。下单前，用户提出想要有人能接一下，跟淳淳约了et9体验，帮他协调，可以去接送他，觉得很尊贵，后面满意锁单\"]\n",
    "ticket_embedding = model.encode(new_ticket)\n",
    " \n",
    "# Calculate similarity features\n",
    "similarity_features = cosine_similarity(ticket_embedding, anchor_embeddings)\n",
    "print(similarity_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf692a11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
